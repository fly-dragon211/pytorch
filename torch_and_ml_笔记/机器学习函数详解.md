# 在typora这里写之后复制到简书上

# 1. CNN

## 建立CNN模型

### 1.import 相关模组
- sequential
- Conv2D
- MaxPooling2D
- Dropout


### 2. 用Sequential开始建模

### 3. convolution and pooling
#### 3.1 卷积层
一个滤镜（矩阵），把本来的图片进行转换，转换之后可以代表之前的一些特征。（放大本来的特征）

长宽压缩，高度增加。
``torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')``
- in_channels: 输入图片的层数
- out_channels: 输出图片的层数
- kernel_size: 过滤器长宽都是5*5
- stride: 每次扫描跳过步数。controls the stride for the cross-correlation, a single number or a tuple.

#### 3.2 池化层

在每一次卷积时，网络可能无意丢失一些信息，这时pooling可以解决。所以pooling后图片大小会发生变化。

- Maxpooling ：最大池化，可以提取每个kernel中最大值。
- avgpooling : 平均值池化。

![maxpooling](https://upload-images.jianshu.io/upload_images/20410282-2360a67ca6ebbfaf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



Conv2d 和 pooling 交替使用
relu = max(0, x)
sigmoid = 1/(1+e^(-x))

- 抛弃层
- 平坦层

**隐藏层(暂时不考虑)**


### 4. 训练模型
定义:
- loss function
- optimizer
- metrics 评分方法

进行训练

- 70%train, 30%test

### 5. 例子
图片大小变化
~~~py
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)  # 28*28 -> (28+1-5)  24*24
        self.conv2 = nn.Conv2d(20, 50, 5, 1) # 20*20 
        self.fc1 = nn.Linear(4*4*50, 500)
        self.fc2 = nn.Linear(500, 10) # 线性层
        
    def forward(self, x):
        # x: 1*28*28
        x = F.relu(self.conv1(x))  # 20*24*24
        x = F.max_pool2d(x, 2, 2)  # 20*12*12
        x = F.relu(self.conv2(x))  # 50*8*8
        x = F.max_pool2d(x, 2, 2)  # 50*4*4
        x = x.view(-1, 4*4*50)  # reshape (5 * 2 * 10), 
        x = F.relu(self.fc1(x)) # 1* (4*4*50)
        x = self.fc2(x)
        # return x
        return F.log_softmax(x, dim=1)  # log probability
    
~~~
[莫烦](https://morvanzhou.github.io/tutorials/machine-learning/torch/4-01-CNN/)
```py
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Sequential(  # input shape (1, 28, 28)
            nn.Conv2d(
                in_channels=1,      # input height
                out_channels=16,    # n_filters
                kernel_size=5,      # filter size
                stride=1,           # filter movement/step
                padding=2,      # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1
            ),      # output shape (16, 28, 28)
            nn.ReLU(),    # activation
            nn.MaxPool2d(kernel_size=2),    # 在 2x2 空间里向下采样, output shape (16, 14, 14)
        )
        self.conv2 = nn.Sequential(  # input shape (16, 14, 14)
            nn.Conv2d(16, 32, 5, 1, 2),  # output shape (32, 14, 14)
            nn.ReLU(),  # activation
            nn.MaxPool2d(2),  # output shape (32, 7, 7)
        )
        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = x.view(x.size(0), -1)   # 展平多维的卷积图成 (batch_size, 32 * 7 * 7)
        output = self.out(x)
        return output

cnn = CNN()
print(cnn)  # net architecture
"""
CNN (
  (conv1): Sequential (
    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): ReLU ()
    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  )
  (conv2): Sequential (
    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): ReLU ()
    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  )
  (out): Linear (1568 -> 10)
)
"""
```



# 2. GAN

## tip

第一次计算D(G(z))时需要 detach ，否则会报错RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.

```python
    artist_paintings = artist_works()
    G_ideas = torch.randn(BATCH_SIZE, N_IDEAS, requires_grad=True)
    G_paintings = G(G_ideas)
    
    prob_artist0 = D(artist_paintings)  # D tries to increase the probability
    prob_artist1 = D(G_paintings.detach())  # D tries to decrease the probability
    D_loss = - torch.mean(torch.log(prob_artist0) + torch.log(1-prob_artist1))
    optim_D.zero_grad()
    D_loss.backward()
    optim_D.step()
```

下面是官网的

```python
        # Generate batch of latent vectors
        noise = torch.randn(b_size, nz, 1, 1, device=device)
        fake_input = netG(noise)
        label.fill_(fake_label)
        # classify all fake image batch with G
        output = netD(fake_input.detach()).view(-1)
        errD_fake = criterion(output, label)
        errD_fake.backward()


```



## 问题

```python
# custom weights initialization called on netG and netD
def weights_init(model):
    classname = model.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(model.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(model.weight.data, 1.0, 0.02)
        nn.init.constant_(model.bias.data, 0.0)
```

我就是把方差0.02写成0.2，结果就没法收敛。。。